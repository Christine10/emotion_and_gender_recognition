{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotionCNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZHIBSYfIxRq5","colab_type":"code","outputId":"53381389-ff3c-4e5d-c3f3-29ef22bae482","executionInfo":{"status":"ok","timestamp":1575530571782,"user_tz":360,"elapsed":73351,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["!git clone https://ChristineTharian@bitbucket.org/ChristineTharian/deeplearning.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'deeplearning'...\n","remote: Counting objects: 10, done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 10 (delta 1), reused 0 (delta 0)\u001b[K\n","Unpacking objects: 100% (10/10), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"27JklFP68a4N","colab_type":"code","colab":{}},"source":["from scipy.io import loadmat\n","import pandas as pd\n","import numpy as np\n","from random import shuffle\n","import os\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5QnOMem9zA2","colab_type":"code","colab":{}},"source":["image_size = (48,48)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2x7m0CN8ILC","colab_type":"code","colab":{}},"source":["data = pd.read_csv('/content/deeplearning/fer2013.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiFFBh6H8JOf","colab_type":"code","colab":{}},"source":["data['emotion'] = data.emotion.apply(lambda x: 1 if x == 3 else 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N3-Syr1fxg8G","colab_type":"code","outputId":"35cdc2ba-1bbe-4fa0-d02a-e26582bdf47f","executionInfo":{"status":"ok","timestamp":1575530776464,"user_tz":360,"elapsed":26674,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["#data = pd.read_csv('/content/deeplearning/fer2013.csv')\n","pixels = data['pixels'].tolist()\n","width, height = 48, 48\n","faces = []\n","for pixel_sequence in pixels:\n","    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n","    face = np.asarray(face).reshape(width, height)\n","    face = cv2.resize(face.astype('uint8'), image_size)\n","    faces.append(face.astype('float32'))\n","faces = np.asarray(faces)\n","faces = np.expand_dims(faces, -1)\n","emotions = pd.get_dummies(data['emotion']).as_matrix()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_r9oXrqB9obV","colab_type":"code","outputId":"7a02cbbd-4291-43b2-a9c2-88b9a0bb8c01","executionInfo":{"status":"ok","timestamp":1575530776466,"user_tz":360,"elapsed":16806,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["data['emotion'].value_counts()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    26898\n","1     8989\n","Name: emotion, dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Gsu9fqMJ_i15","colab_type":"code","outputId":"2cf3ad19-db7a-4baa-a38a-4485aefc47fd","executionInfo":{"status":"ok","timestamp":1575530788366,"user_tz":360,"elapsed":3289,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["import sys, os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.losses import categorical_crossentropy\n","from keras.optimizers import Adam\n","from keras.regularizers import l2"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Bo1JLCUmk1QH","colab_type":"code","colab":{}},"source":["num_features = 64\n","#num_labels = 7\n","num_labels = 2\n","batch_size = 64\n","epochs = 100\n","width, height = 48, 48\n","\n","x = faces\n","y = emotions\n","\n","def preprocess_input(x, v2=True):\n","    x = x.astype('float32')\n","    x = x / 255.0\n","    if v2:\n","        x = x - 0.5\n","        x = x * 2.0\n","    return x\n","\n","# x -= np.mean(x, axis=0)\n","# x /= np.std(x, axis=0)\n","\n","preprocess_input(x)\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C11kofuDm1Y1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6f401e39-d4a5-46e4-b45e-f173991a85e2","executionInfo":{"status":"ok","timestamp":1575530817007,"user_tz":360,"elapsed":5023,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}}},"source":["model = Sequential()\n","\n","model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n","model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(2*2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*num_features, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_labels, activation='softmax'))\n","\n","model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               1049088   \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 5,905,218\n","Trainable params: 5,901,506\n","Non-trainable params: 3,712\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUKQo9hvm3Fo","colab_type":"code","outputId":"09fd4334-26f0-4948-b3e7-d53d82700475","executionInfo":{"status":"ok","timestamp":1575538459488,"user_tz":360,"elapsed":7630252,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(loss=categorical_crossentropy,\n","              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n","              metrics=['accuracy'])\n","\n","#training the model\n","\n","\n","\n","# fit model\n","n_epochs, n_save_after = 100, 70\n","for i in range(n_epochs):\n","\t# fit model for a single epoch\n","  print(i)\n","  model.fit(X_train, y_train, epochs=1, verbose=1, validation_data=(np.array(X_valid), np.array(y_valid)))\n","\t# check if we should save the model\n","  if i >= n_save_after:\n","  \tmodel.save('model_' + str(i) + '.h5')\n","# model.fit(np.array(X_train), np.array(y_train),\n","#           batch_size=batch_size,\n","#           epochs=30,\n","#           verbose=1,\n","#           validation_data=(np.array(X_valid), np.array(y_valid)),\n","#           shuffle=True)\n","\n","# #saving the  model to be used later\n","# fer_json = model.to_json()\n","# with open(\"fer.json\", \"w\") as json_file:\n","#     json_file.write(fer_json)\n","# model.save_weights(\"fer.h5\")\n","# print(\"Saved model to disk\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 84s 3ms/step - loss: 0.7134 - acc: 0.7264 - val_loss: 0.5935 - val_acc: 0.7406\n","1\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.5766 - acc: 0.7493 - val_loss: 0.5829 - val_acc: 0.7406\n","2\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.5123 - acc: 0.7673 - val_loss: 0.4580 - val_acc: 0.8266\n","3\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.3984 - acc: 0.8336 - val_loss: 0.3388 - val_acc: 0.8582\n","4\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.3423 - acc: 0.8642 - val_loss: 0.3020 - val_acc: 0.8845\n","5\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.3204 - acc: 0.8763 - val_loss: 0.3024 - val_acc: 0.8836\n","6\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.3022 - acc: 0.8859 - val_loss: 0.3360 - val_acc: 0.8842\n","7\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2881 - acc: 0.8923 - val_loss: 0.2660 - val_acc: 0.9031\n","8\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2757 - acc: 0.8981 - val_loss: 0.2617 - val_acc: 0.8988\n","9\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2582 - acc: 0.9059 - val_loss: 0.2728 - val_acc: 0.9062\n","10\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2493 - acc: 0.9096 - val_loss: 0.2364 - val_acc: 0.9121\n","11\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2373 - acc: 0.9133 - val_loss: 0.2970 - val_acc: 0.8873\n","12\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2325 - acc: 0.9157 - val_loss: 0.2644 - val_acc: 0.9059\n","13\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2161 - acc: 0.9231 - val_loss: 0.3016 - val_acc: 0.8684\n","14\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.2060 - acc: 0.9262 - val_loss: 0.3069 - val_acc: 0.9121\n","15\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1975 - acc: 0.9312 - val_loss: 0.2336 - val_acc: 0.9133\n","16\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1949 - acc: 0.9319 - val_loss: 0.2461 - val_acc: 0.9065\n","17\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1881 - acc: 0.9322 - val_loss: 0.2573 - val_acc: 0.9173\n","18\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1778 - acc: 0.9389 - val_loss: 0.2417 - val_acc: 0.9130\n","19\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1687 - acc: 0.9420 - val_loss: 0.2622 - val_acc: 0.9105\n","20\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1586 - acc: 0.9426 - val_loss: 0.2476 - val_acc: 0.9149\n","21\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1555 - acc: 0.9452 - val_loss: 0.2600 - val_acc: 0.9146\n","22\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1545 - acc: 0.9455 - val_loss: 0.2431 - val_acc: 0.9170\n","23\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1439 - acc: 0.9499 - val_loss: 0.2704 - val_acc: 0.9195\n","24\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1381 - acc: 0.9530 - val_loss: 0.2602 - val_acc: 0.9170\n","25\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1359 - acc: 0.9542 - val_loss: 0.2780 - val_acc: 0.9149\n","26\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1282 - acc: 0.9567 - val_loss: 0.2590 - val_acc: 0.9139\n","27\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1225 - acc: 0.9568 - val_loss: 0.2958 - val_acc: 0.9127\n","28\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1268 - acc: 0.9554 - val_loss: 0.2796 - val_acc: 0.9028\n","29\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1169 - acc: 0.9604 - val_loss: 0.3072 - val_acc: 0.9183\n","30\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1149 - acc: 0.9605 - val_loss: 0.2860 - val_acc: 0.9207\n","31\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1194 - acc: 0.9595 - val_loss: 0.2854 - val_acc: 0.9142\n","32\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1196 - acc: 0.9599 - val_loss: 0.2925 - val_acc: 0.9164\n","33\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1154 - acc: 0.9627 - val_loss: 0.2431 - val_acc: 0.9173\n","34\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1068 - acc: 0.9645 - val_loss: 0.2772 - val_acc: 0.9211\n","35\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1107 - acc: 0.9614 - val_loss: 0.2611 - val_acc: 0.9158\n","36\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1031 - acc: 0.9653 - val_loss: 0.2693 - val_acc: 0.9173\n","37\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0998 - acc: 0.9675 - val_loss: 0.2680 - val_acc: 0.9155\n","38\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1038 - acc: 0.9675 - val_loss: 0.2713 - val_acc: 0.9201\n","39\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0962 - acc: 0.9673 - val_loss: 0.2806 - val_acc: 0.9077\n","40\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0972 - acc: 0.9685 - val_loss: 0.2995 - val_acc: 0.9170\n","41\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.1031 - acc: 0.9657 - val_loss: 0.2911 - val_acc: 0.9127\n","42\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0895 - acc: 0.9702 - val_loss: 0.3009 - val_acc: 0.9142\n","43\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0941 - acc: 0.9686 - val_loss: 0.3342 - val_acc: 0.9009\n","44\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0930 - acc: 0.9706 - val_loss: 0.2754 - val_acc: 0.9158\n","45\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0929 - acc: 0.9715 - val_loss: 0.2625 - val_acc: 0.9130\n","46\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 77s 3ms/step - loss: 0.0944 - acc: 0.9708 - val_loss: 0.2933 - val_acc: 0.9124\n","47\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0922 - acc: 0.9704 - val_loss: 0.2966 - val_acc: 0.9201\n","48\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0850 - acc: 0.9723 - val_loss: 0.2836 - val_acc: 0.9183\n","49\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0842 - acc: 0.9740 - val_loss: 0.2643 - val_acc: 0.9170\n","50\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0801 - acc: 0.9749 - val_loss: 0.3585 - val_acc: 0.9176\n","51\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0871 - acc: 0.9748 - val_loss: 0.3269 - val_acc: 0.9183\n","52\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0899 - acc: 0.9713 - val_loss: 0.2955 - val_acc: 0.9192\n","53\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0881 - acc: 0.9719 - val_loss: 0.2965 - val_acc: 0.9115\n","54\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0868 - acc: 0.9721 - val_loss: 0.3423 - val_acc: 0.9204\n","55\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0756 - acc: 0.9757 - val_loss: 0.3074 - val_acc: 0.9183\n","56\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0807 - acc: 0.9751 - val_loss: 0.3718 - val_acc: 0.9087\n","57\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0884 - acc: 0.9726 - val_loss: 0.3330 - val_acc: 0.9189\n","58\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0774 - acc: 0.9768 - val_loss: 0.3136 - val_acc: 0.9173\n","59\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0735 - acc: 0.9762 - val_loss: 0.3057 - val_acc: 0.9186\n","60\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0899 - acc: 0.9725 - val_loss: 0.2960 - val_acc: 0.9201\n","61\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0730 - acc: 0.9769 - val_loss: 0.3486 - val_acc: 0.9211\n","62\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0761 - acc: 0.9751 - val_loss: 0.3790 - val_acc: 0.9223\n","63\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0765 - acc: 0.9774 - val_loss: 0.3038 - val_acc: 0.9192\n","64\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0733 - acc: 0.9763 - val_loss: 0.2832 - val_acc: 0.9142\n","65\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0717 - acc: 0.9786 - val_loss: 0.3285 - val_acc: 0.9220\n","66\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0886 - acc: 0.9725 - val_loss: 0.3501 - val_acc: 0.9170\n","67\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0709 - acc: 0.9800 - val_loss: 0.3160 - val_acc: 0.9155\n","68\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0792 - acc: 0.9767 - val_loss: 0.3231 - val_acc: 0.9198\n","69\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0958 - acc: 0.9702 - val_loss: 0.3147 - val_acc: 0.9170\n","70\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0692 - acc: 0.9794 - val_loss: 0.3250 - val_acc: 0.9251\n","71\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0642 - acc: 0.9795 - val_loss: 0.2926 - val_acc: 0.9176\n","72\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0714 - acc: 0.9787 - val_loss: 0.2876 - val_acc: 0.9158\n","73\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0695 - acc: 0.9796 - val_loss: 0.4066 - val_acc: 0.9220\n","74\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0717 - acc: 0.9773 - val_loss: 0.4547 - val_acc: 0.9189\n","75\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0763 - acc: 0.9764 - val_loss: 0.3169 - val_acc: 0.9080\n","76\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0700 - acc: 0.9784 - val_loss: 0.3483 - val_acc: 0.9232\n","77\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0623 - acc: 0.9805 - val_loss: 0.3731 - val_acc: 0.9248\n","78\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0721 - acc: 0.9789 - val_loss: 0.3443 - val_acc: 0.9189\n","79\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0642 - acc: 0.9806 - val_loss: 0.3484 - val_acc: 0.9161\n","80\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0585 - acc: 0.9837 - val_loss: 0.3285 - val_acc: 0.9251\n","81\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0664 - acc: 0.9794 - val_loss: 0.3525 - val_acc: 0.9167\n","82\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0548 - acc: 0.9840 - val_loss: 0.3710 - val_acc: 0.9195\n","83\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0648 - acc: 0.9821 - val_loss: 0.3155 - val_acc: 0.9074\n","84\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0869 - acc: 0.9766 - val_loss: 0.3009 - val_acc: 0.9176\n","85\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0647 - acc: 0.9801 - val_loss: 0.3518 - val_acc: 0.9164\n","86\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0692 - acc: 0.9809 - val_loss: 0.2969 - val_acc: 0.9170\n","87\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0694 - acc: 0.9813 - val_loss: 0.3425 - val_acc: 0.9204\n","88\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0607 - acc: 0.9822 - val_loss: 0.3656 - val_acc: 0.9226\n","89\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0658 - acc: 0.9805 - val_loss: 0.4250 - val_acc: 0.9204\n","90\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0661 - acc: 0.9810 - val_loss: 0.3059 - val_acc: 0.9130\n","91\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0713 - acc: 0.9776 - val_loss: 0.3796 - val_acc: 0.9155\n","92\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0695 - acc: 0.9802 - val_loss: 0.3194 - val_acc: 0.9189\n","93\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0556 - acc: 0.9830 - val_loss: 0.4074 - val_acc: 0.9223\n","94\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0578 - acc: 0.9849 - val_loss: 0.4245 - val_acc: 0.9071\n","95\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0733 - acc: 0.9797 - val_loss: 0.3538 - val_acc: 0.9108\n","96\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0641 - acc: 0.9819 - val_loss: 0.3454 - val_acc: 0.9198\n","97\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0643 - acc: 0.9813 - val_loss: 0.3014 - val_acc: 0.9152\n","98\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0673 - acc: 0.9790 - val_loss: 0.3294 - val_acc: 0.9211\n","99\n","Train on 29068 samples, validate on 3230 samples\n","Epoch 1/1\n","29068/29068 [==============================] - 76s 3ms/step - loss: 0.0679 - acc: 0.9803 - val_loss: 0.4889 - val_acc: 0.8796\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iwnRuXNMfaCe","colab_type":"code","colab":{}},"source":["model.save('hope.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kB1ZunJh_MZ","colab_type":"code","colab":{}},"source":["model.save_weights('old.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKdfg6fctjny","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","\n","def load_all_models(n_start, n_end):\n","\tall_models = list()\n","\tfor epoch in range(n_start, n_end):\n","\t\t# define filename for this ensemble\n","\t\tfilename = 'model_' + str(epoch) + '.h5'\n","\t\t# load model from file\n","\t\tmodel = load_model(filename)\n","\t\t# add to list of members\n","\t\tall_models.append(model)\n","\t\tprint('>loaded %s' % filename)\n","\treturn all_models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFeP_JrGnPzq","colab_type":"code","colab":{}},"source":["def ensemble_predictions(members, testX):\n","\t# make predictions\n","\tyhats = [model.predict(testX, verbose = 1) for model in members]\n","\tyhats = np.array(yhats)\n","\t# sum across ensemble members\n","\tsummed = np.sum(yhats, axis=0)\n","\t# argmax across classes\n","\tresult = np.argmax(summed, axis=1)\n","\treturn result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqQRbDcgOFC1","colab_type":"code","outputId":"1bd0d014-69d8-466b-9f1b-17be4e99e7bf","executionInfo":{"status":"ok","timestamp":1574977555929,"user_tz":360,"elapsed":199727,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":745}},"source":["members = load_all_models(70, 100)\n","preds = ensemble_predictions(members, X_test)\n","temp = sum(np.argmax(y_test, axis=1) == preds)\n","temp/len(y_test) "],"execution_count":0,"outputs":[{"output_type":"stream","text":[">loaded model_30.h5\n",">loaded model_31.h5\n",">loaded model_32.h5\n",">loaded model_33.h5\n",">loaded model_34.h5\n",">loaded model_35.h5\n",">loaded model_36.h5\n",">loaded model_37.h5\n",">loaded model_38.h5\n",">loaded model_39.h5\n",">loaded model_40.h5\n",">loaded model_41.h5\n",">loaded model_42.h5\n",">loaded model_43.h5\n",">loaded model_44.h5\n",">loaded model_45.h5\n",">loaded model_46.h5\n",">loaded model_47.h5\n",">loaded model_48.h5\n",">loaded model_49.h5\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n","3589/3589 [==============================] - 10s 3ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.6609083310114238"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"thHK1tWTPI1q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}