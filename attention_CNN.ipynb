{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attention_CNN.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Jf1uI3oJ0my0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2d2e303a-d915-44ca-d657-9a8f7ec1d480","executionInfo":{"status":"ok","timestamp":1575490721107,"user_tz":360,"elapsed":29469,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}}},"source":["!pip install --upgrade tensorflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 44.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 59.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.1)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n","\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n","Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed google-auth-1.7.1 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8VBLc-x_CrhV","colab_type":"code","outputId":"24993891-3a54-4a63-c738-add96f0d6889","executionInfo":{"status":"ok","timestamp":1575490723892,"user_tz":360,"elapsed":32238,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":303}},"source":["!pip install --upgrade keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting keras\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\r\u001b[K     |▉                               | 10kB 28.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.2.5\n","    Uninstalling Keras-2.2.5:\n","      Successfully uninstalled Keras-2.2.5\n","Successfully installed keras-2.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ehoAL_-Hu2vx","colab_type":"code","outputId":"fdd64d0a-8094-4308-a5fa-4bfd33a4d20a","executionInfo":{"status":"ok","timestamp":1575490781285,"user_tz":360,"elapsed":54157,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["!git clone https://ChristineTharian@bitbucket.org/ChristineTharian/deeplearning.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'deeplearning'...\n","remote: Counting objects: 10, done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 10 (delta 1), reused 0 (delta 0)\u001b[K\n","Unpacking objects: 100% (10/10), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Uw9J7F1u96q","colab_type":"code","colab":{}},"source":["from scipy.io import loadmat\n","import pandas as pd\n","import numpy as np\n","from random import shuffle\n","import os\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"us9TutHFvBAX","colab_type":"code","colab":{}},"source":["image_size = (48,48)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZ_bN9_WvM7I","colab_type":"code","outputId":"1077e830-4d88-457c-8ab0-95538b731adb","executionInfo":{"status":"ok","timestamp":1575490803416,"user_tz":360,"elapsed":70530,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["data = pd.read_csv('/content/deeplearning/fer2013.csv')\n","pixels = data['pixels'].tolist()\n","width, height = 48, 48\n","faces = []\n","for pixel_sequence in pixels:\n","    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n","    face = np.asarray(face).reshape(width, height)\n","    face = cv2.resize(face.astype('uint8'), image_size)\n","    faces.append(face.astype('float32'))\n","faces = np.asarray(faces)\n","faces = np.expand_dims(faces, -1)\n","emotions = pd.get_dummies(data['emotion']).as_matrix()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cIQ93j41vdr3","colab_type":"code","colab":{}},"source":["import sys, os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qf9H9Su9vQS_","colab_type":"code","colab":{}},"source":["num_features = 64\n","num_labels = 7\n","batch_size = 64\n","epochs = 100\n","width, height = 48, 48\n","\n","x = faces\n","y = emotions\n","\n","def preprocess_input(x, v2=True):\n","    x = x.astype('float32')\n","    x = x / 255.0\n","    if v2:\n","        x = x - 0.5\n","        x = x * 2.0\n","    return x\n","\n","# x -= np.mean(x, axis=0)\n","# x /= np.std(x, axis=0)\n","\n","preprocess_input(x)\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsP26B-ovu7L","colab_type":"code","colab":{}},"source":["def get_initial_weights(output_size):\n","    b = np.zeros((2, 3), dtype='float32')\n","    b[0, 0] = 1\n","    b[1, 1] = 1\n","    W = np.zeros((output_size, 6), dtype='float32')\n","    weights = [W, b.flatten()]\n","    return weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-x4Kx7stv-1q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"390458af-9fed-45ab-b445-f994ee2dd1e5","executionInfo":{"status":"ok","timestamp":1575490806097,"user_tz":360,"elapsed":57866,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}}},"source":["from keras import backend as K\n","from keras.engine.topology import Layer\n","\n","if K.backend() == 'tensorflow':\n","    import tensorflow as tf\n","\n","    def K_meshgrid(x, y):\n","        return tf.meshgrid(x, y)\n","\n","    def K_linspace(start, stop, num):\n","        return tf.linspace(start, stop, num)\n","\n","else:\n","    raise Exception(\"Only 'tensorflow' is supported as backend\")\n","\n","class BilinearInterpolation(Layer):\n","    \"\"\"Performs bilinear interpolation as a keras layer\n","    References\n","    ----------\n","    [1]  Spatial Transformer Networks, Max Jaderberg, et al.\n","    [2]  https://github.com/skaae/transformer_network\n","    [3]  https://github.com/EderSantana/seya\n","    \"\"\"\n","\n","    def __init__(self, output_size, **kwargs):\n","        self.output_size = output_size\n","        super(BilinearInterpolation, self).__init__(**kwargs)\n","\n","    def get_config(self):\n","        return {\n","            'output_size': self.output_size,\n","        }\n","\n","    def compute_output_shape(self, input_shapes):\n","        height, width = self.output_size\n","        num_channels = input_shapes[0][-1]\n","        return (None, height, width, num_channels)\n","\n","    def call(self, tensors, mask=None):\n","        X, transformation = tensors\n","        output = self._transform(X, transformation, self.output_size)\n","        return output\n","\n","    def _interpolate(self, image, sampled_grids, output_size):\n","\n","        batch_size = K.shape(image)[0]\n","        height = K.shape(image)[1]\n","        width = K.shape(image)[2]\n","        num_channels = K.shape(image)[3]\n","\n","        x = K.cast(K.flatten(sampled_grids[:, 0:1, :]), dtype='float32')\n","        y = K.cast(K.flatten(sampled_grids[:, 1:2, :]), dtype='float32')\n","\n","        x = .5 * (x + 1.0) * K.cast(width, dtype='float32')\n","        y = .5 * (y + 1.0) * K.cast(height, dtype='float32')\n","\n","        x0 = K.cast(x, 'int32')\n","        x1 = x0 + 1\n","        y0 = K.cast(y, 'int32')\n","        y1 = y0 + 1\n","\n","        max_x = int(K.int_shape(image)[2] - 1)\n","        max_y = int(K.int_shape(image)[1] - 1)\n","\n","        x0 = K.clip(x0, 0, max_x)\n","        x1 = K.clip(x1, 0, max_x)\n","        y0 = K.clip(y0, 0, max_y)\n","        y1 = K.clip(y1, 0, max_y)\n","\n","        pixels_batch = K.arange(0, batch_size) * (height * width)\n","        pixels_batch = K.expand_dims(pixels_batch, axis=-1)\n","        flat_output_size = output_size[0] * output_size[1]\n","        base = K.repeat_elements(pixels_batch, flat_output_size, axis=1)\n","        base = K.flatten(base)\n","\n","        # base_y0 = base + (y0 * width)\n","        base_y0 = y0 * width\n","        base_y0 = base + base_y0\n","        # base_y1 = base + (y1 * width)\n","        base_y1 = y1 * width\n","        base_y1 = base_y1 + base\n","\n","        indices_a = base_y0 + x0\n","        indices_b = base_y1 + x0\n","        indices_c = base_y0 + x1\n","        indices_d = base_y1 + x1\n","\n","        flat_image = K.reshape(image, shape=(-1, num_channels))\n","        flat_image = K.cast(flat_image, dtype='float32')\n","        pixel_values_a = K.gather(flat_image, indices_a)\n","        pixel_values_b = K.gather(flat_image, indices_b)\n","        pixel_values_c = K.gather(flat_image, indices_c)\n","        pixel_values_d = K.gather(flat_image, indices_d)\n","\n","        x0 = K.cast(x0, 'float32')\n","        x1 = K.cast(x1, 'float32')\n","        y0 = K.cast(y0, 'float32')\n","        y1 = K.cast(y1, 'float32')\n","\n","        area_a = K.expand_dims(((x1 - x) * (y1 - y)), 1)\n","        area_b = K.expand_dims(((x1 - x) * (y - y0)), 1)\n","        area_c = K.expand_dims(((x - x0) * (y1 - y)), 1)\n","        area_d = K.expand_dims(((x - x0) * (y - y0)), 1)\n","\n","        values_a = area_a * pixel_values_a\n","        values_b = area_b * pixel_values_b\n","        values_c = area_c * pixel_values_c\n","        values_d = area_d * pixel_values_d\n","        return values_a + values_b + values_c + values_d\n","\n","    def _make_regular_grids(self, batch_size, height, width):\n","        # making a single regular grid\n","        x_linspace = K_linspace(-1., 1., width)\n","        y_linspace = K_linspace(-1., 1., height)\n","        x_coordinates, y_coordinates = K_meshgrid(x_linspace, y_linspace)\n","        x_coordinates = K.flatten(x_coordinates)\n","        y_coordinates = K.flatten(y_coordinates)\n","        ones = K.ones_like(x_coordinates)\n","        grid = K.concatenate([x_coordinates, y_coordinates, ones], 0)\n","\n","        # repeating grids for each batch\n","        grid = K.flatten(grid)\n","        grids = K.tile(grid, K.stack([batch_size]))\n","        return K.reshape(grids, (batch_size, 3, height * width))\n","\n","    def _transform(self, X, affine_transformation, output_size):\n","        batch_size, num_channels = K.shape(X)[0], K.shape(X)[3]\n","        transformations = K.reshape(affine_transformation,\n","                                    shape=(batch_size, 2, 3))\n","        # transformations = K.cast(affine_transformation[:, 0:2, :], 'float32')\n","        regular_grids = self._make_regular_grids(batch_size, *output_size)\n","        sampled_grids = K.batch_dot(transformations, regular_grids)\n","        interpolated_image = self._interpolate(X, sampled_grids, output_size)\n","        new_shape = (batch_size, output_size[0], output_size[1], num_channels)\n","        interpolated_image = K.reshape(interpolated_image, new_shape)\n","        return interpolated_image"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xySEiQ68vZIp","colab_type":"code","colab":{}},"source":["from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import Activation\n","from keras.layers import MaxPool2D\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Dense\n","from keras.layers import BatchNormalization\n","\n","def STN(input_shape=(48, 48, 1), sampling_size=(30, 30), num_classes=7):\n","    image = Input(shape=input_shape)\n","    locnet = Conv2D(8, (3, 3))(image)\n","    locnet = Activation('relu')(locnet)\n","    locnet = BatchNormalization()(locnet)\n","    locnet = MaxPool2D(pool_size=(2, 2))(locnet)\n","    locnet = Conv2D(10, (3, 3))(locnet)\n","    locnet = Activation('relu')(locnet)\n","    locnet = Activation('relu')(locnet)\n","    locnet = Flatten()(locnet)\n","    # locnet = Dense(90)(locnet)\n","    locnet = Dense(50)(locnet)\n","    locnet = Activation('relu')(locnet)\n","    weights = get_initial_weights(50)\n","    locnet = Dense(6, weights=weights)(locnet)\n","    x = BilinearInterpolation(sampling_size)([image, locnet])\n","    x = Conv2D(10, (3, 3), padding='same')(x)\n","    x = Activation('relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(10, (3, 3), padding='same')(x)\n","    x = Activation('relu')(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPool2D(pool_size=(2, 2))(x)\n","    x = Conv2D(10, (3, 3))(x)\n","    x = Activation('relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(10, (3, 3))(x)\n","    x = Activation('relu')(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPool2D(pool_size=(2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(50)(x)\n","    x = Activation('relu')(x)\n","    x = Dense(num_classes)(x)\n","    x = Activation('softmax')(x)\n","    return Model(inputs=image, outputs=x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U70dzqe5ymdd","colab_type":"code","outputId":"a6c35585-9a44-4307-e431-2e36ff3bc6df","executionInfo":{"status":"ok","timestamp":1575493659314,"user_tz":360,"elapsed":594,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import keras\n","model = STN()\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 48, 48, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 46, 46, 8)    80          input_3[0][0]                    \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 46, 46, 8)    0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 46, 46, 8)    32          activation_11[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 23, 23, 8)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 21, 21, 10)   730         max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 21, 21, 10)   0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 21, 21, 10)   0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 4410)         0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 50)           220550      flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 50)           0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 6)            306         activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bilinear_interpolation_2 (Bilin (None, 30, 30, 1)    0           input_3[0][0]                    \n","                                                                 dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 30, 30, 10)   100         bilinear_interpolation_2[0][0]   \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 30, 30, 10)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 30, 30, 10)   40          activation_15[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 30, 30, 10)   910         batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 30, 30, 10)   0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 30, 30, 10)   40          activation_16[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 15, 15, 10)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 13, 13, 10)   910         max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 13, 13, 10)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 13, 13, 10)   40          activation_17[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 11, 11, 10)   910         batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 11, 11, 10)   0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 11, 11, 10)   40          activation_18[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 5, 5, 10)     0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 250)          0           max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 50)           12550       flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 50)           0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 7)            357         activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 7)            0           dense_8[0][0]                    \n","==================================================================================================\n","Total params: 237,595\n","Trainable params: 237,499\n","Non-trainable params: 96\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hoikkcL3zVSg","colab_type":"code","outputId":"cd9d52fd-d732-48ff-fddf-3dda93998ee8","executionInfo":{"status":"ok","timestamp":1575358205443,"user_tz":360,"elapsed":758559,"user":{"displayName":"Vivek Goddu","photoUrl":"","userId":"06244962268141392132"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["K.set_value(model.optimizer.lr, 0.005)\n","keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n","model.fit(X_train, y_train, epochs=30, verbose=1, validation_data=(np.array(X_valid), np.array(y_valid)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 29068 samples, validate on 3230 samples\n","Epoch 1/30\n","29068/29068 [==============================] - 84s 3ms/step - loss: 1.8351 - accuracy: 0.2435 - val_loss: 3.5280 - val_accuracy: 0.2594\n","Epoch 2/30\n","29068/29068 [==============================] - 82s 3ms/step - loss: 1.8149 - accuracy: 0.2501 - val_loss: 106.8510 - val_accuracy: 0.1715\n","Epoch 3/30\n"," 3424/29068 [==>...........................] - ETA: 1:15 - loss: 1.8145 - accuracy: 0.2593"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j6jb-mM-Dm0B","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}